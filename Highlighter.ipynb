{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHZtOWKvKxZs"
      },
      "outputs": [],
      "source": [
        "\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import tempfile\n",
        "import shutil\n",
        "import fitz\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "def is_image_file(path):\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    return ext in ('.png', '.jpg', '.jpeg', '.tiff', '.tif', '.bmp')\n",
        "\n",
        "def is_pdf(path):\n",
        "    return os.path.splitext(path)[1].lower() == '.pdf'\n",
        "\n",
        "def is_docx(path):\n",
        "    return os.path.splitext(path)[1].lower() == '.docx'\n",
        "\n",
        "def is_xlsx(path):\n",
        "    return os.path.splitext(path)[1].lower() == '.xlsx'\n",
        "\n",
        "def convert_to_pdf_with_libreoffice(src_path, out_dir):\n",
        "    \"\"\"\n",
        "    Try to convert docx/xlsx to pdf using libreoffice (soffice) headless.\n",
        "    Returns path to converted pdf or None on failure.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        cmd = [\n",
        "            'soffice', '--headless', '--convert-to', 'pdf', '--outdir',\n",
        "            out_dir, src_path\n",
        "        ]\n",
        "        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        base = os.path.splitext(os.path.basename(src_path))[0] + '.pdf'\n",
        "        out_pdf = os.path.join(out_dir, base)\n",
        "        if os.path.exists(out_pdf):\n",
        "            return out_pdf\n",
        "    except Exception as e:\n",
        "        # Conversion failed\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "def render_page_to_image(pdf_path, page_number, zoom=2):\n",
        "    \"\"\"\n",
        "    Render a PDF page to a PIL image using PyMuPDF.\n",
        "    zoom parameter scales the output to improve OCR accuracy.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    page = doc.load_page(page_number)\n",
        "    mat = fitz.Matrix(zoom, zoom)\n",
        "    pix = page.get_pixmap(matrix=mat, alpha=False)\n",
        "    mode = \"RGB\"\n",
        "    img = Image.frombytes(mode, [pix.width, pix.height], pix.samples)\n",
        "    doc.close()\n",
        "    return img\n",
        "\n",
        "def image_to_ocr_data(pil_image):\n",
        "    \"\"\"\n",
        "    Return pytesseract image_to_data output (list of dicts)\n",
        "    Each dict contains: level, page_num, block_num, par_num, line_num, word_num, left, top, width, height, conf, text\n",
        "    \"\"\"\n",
        "    raw = pytesseract.image_to_data(pil_image, output_type=pytesseract.Output.DICT)\n",
        "    n = len(raw['text'])\n",
        "    data = []\n",
        "    for i in range(n):\n",
        "        text = raw['text'][i].strip()\n",
        "        if text == \"\":\n",
        "            # keep empty tokens if needed\n",
        "            pass\n",
        "        data.append({\n",
        "            'text': text,\n",
        "            'left': int(raw['left'][i]),\n",
        "            'top': int(raw['top'][i]),\n",
        "            'width': int(raw['width'][i]),\n",
        "            'height': int(raw['height'][i]),\n",
        "            'conf': int(raw['conf'][i]) if raw['conf'][i] != '-1' else -1,\n",
        "            'line_num': int(raw['line_num'][i]),\n",
        "            'word_num': int(raw['word_num'][i]),\n",
        "        })\n",
        "    return data\n",
        "\n",
        "def find_matches_in_ocr_data(ocr_data, search_text):\n",
        "    \"\"\"\n",
        "    Given OCR token list for a page (in reading order), find occurrences of search_text (case-insensitive).\n",
        "    Strategy:\n",
        "      - Group tokens by line_num\n",
        "      - For each line, build a concatenated string with spaces and track token indices.\n",
        "      - Find substring matches; map back to tokens to compute bounding box union.\n",
        "    Returns list of bounding boxes [ (left, top, right, bottom) ... ] in image pixel coordinates.\n",
        "    \"\"\"\n",
        "    s = search_text.strip().lower()\n",
        "    if not s:\n",
        "        return []\n",
        "    matches = []\n",
        "    # group by line_num preserving order\n",
        "    from collections import defaultdict, OrderedDict\n",
        "    lines = OrderedDict()\n",
        "    for idx, tok in enumerate(ocr_data):\n",
        "        ln = tok['line_num']\n",
        "        lines.setdefault(ln, []).append((idx, tok))\n",
        "\n",
        "    for ln, toks in lines.items():\n",
        "        words = [t[1]['text'] for t in toks]\n",
        "        # Reconstruct line string with single spaces. Keep mapping from char index to token index.\n",
        "        line_str = \"\"\n",
        "        char_to_token = []\n",
        "        for ti, (_, tok) in enumerate(toks):\n",
        "            if ti > 0:\n",
        "                line_str += \" \"\n",
        "                char_to_token.append(None)  # for space\n",
        "            token_text = tok['text']\n",
        "            token_lower = token_text.lower()\n",
        "            start = len(line_str)\n",
        "            line_str += token_text\n",
        "            for _ in token_text:\n",
        "                char_to_token.append(ti)  # token index in toks\n",
        "        # find all occurrences of s in line_str\n",
        "        start_idx = 0\n",
        "        while True:\n",
        "            found = line_str.find(s, start_idx)\n",
        "            if found == -1:\n",
        "                break\n",
        "            # map char range to token indices\n",
        "            char_idxs = range(found, found + len(s))\n",
        "            token_idxs = set()\n",
        "            for ci in char_idxs:\n",
        "                if ci < len(char_to_token):\n",
        "                    mapped = char_to_token[ci]\n",
        "                    if mapped is not None:\n",
        "                        token_idxs.add(mapped)\n",
        "            if not token_idxs:\n",
        "                start_idx = found + 1\n",
        "                continue\n",
        "            # tokens indices are relative to toks list\n",
        "            token_idxs_sorted = sorted(token_idxs)\n",
        "            # compute bounding box union of tokens\n",
        "            lefts = []\n",
        "            tops = []\n",
        "            rights = []\n",
        "            bottoms = []\n",
        "            for tindex in token_idxs_sorted:\n",
        "                tok = toks[tindex][1]\n",
        "                l = tok['left']; t = tok['top']; w = tok['width']; h = tok['height']\n",
        "                lefts.append(l); tops.append(t); rights.append(l + w); bottoms.append(t + h)\n",
        "            left = min(lefts); top = min(tops); right = max(rights); bottom = max(bottoms)\n",
        "            matches.append((left, top, right, bottom))\n",
        "            start_idx = found + 1\n",
        "    return matches\n",
        "\n",
        "def add_rectangles_to_pdf(input_pdf_path, matches_per_page, out_pdf_path, zoom=2):\n",
        "    \"\"\"\n",
        "    Add unfilled red rectangles to the PDF pages using PyMuPDF.\n",
        "    matches_per_page: dict page_idx -> list of boxes in image pixel coords (on rendered image with same zoom)\n",
        "    Need to convert image pixel coords back to PDF coordinate space.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(input_pdf_path)\n",
        "    for page_idx, page in enumerate(doc):\n",
        "        page_matches = matches_per_page.get(page_idx, [])\n",
        "        if not page_matches:\n",
        "            continue\n",
        "        # page rect in PDF points\n",
        "        page_rect = page.rect\n",
        "        # compute scaling between rendered image (zoom) and PDF points\n",
        "        # When we rendered we used zoom factor, and PyMuPDF default resolution 72 dpi: image px = pdf points * zoom\n",
        "        # So to convert image px -> pdf points: pdf_x = px / zoom\n",
        "        scale = 1.0 / zoom\n",
        "        for (l, t, r, b) in page_matches:\n",
        "            # convert image pixel coords to pdf coordinates\n",
        "            pdf_left = l * scale\n",
        "            pdf_top = t * scale\n",
        "            pdf_right = r * scale\n",
        "            pdf_bottom = b * scale\n",
        "            # PyMuPDF coordinate origin for page is (0,0) top-left in text extraction, but fitz.Rect uses points where y grows down.\n",
        "            # Create a rect\n",
        "            rect = fitz.Rect(pdf_left, pdf_top, pdf_right, pdf_bottom)\n",
        "            # Add a rectangle annotation: red border, no fill\n",
        "            annot = page.add_rect_annot(rect)\n",
        "            annot.set_colors(stroke=(1, 0, 0))  # red\n",
        "            annot.set_border(width=1)  # 1pt border\n",
        "            annot.update()  # apply\n",
        "    doc.save(out_pdf_path, garbage=4, deflate=True)\n",
        "    doc.close()\n",
        "\n",
        "\n",
        "def process_file(input_path, search_text, out_dir=None, zoom=3):\n",
        "    if out_dir is None:\n",
        "        out_dir = os.path.dirname(os.path.abspath(input_path)) or os.getcwd()\n",
        "    basename = os.path.splitext(os.path.basename(input_path))[0]\n",
        "    tmpdir = tempfile.mkdtemp(prefix=\"auditram_\")\n",
        "    try:\n",
        "        working_pdf = None\n",
        "        # If docx/xlsx, try to convert to pdf\n",
        "        if is_docx(input_path) or is_xlsx(input_path):\n",
        "            conv = convert_to_pdf_with_libreoffice(input_path, tmpdir)\n",
        "            if conv:\n",
        "                working_pdf = conv\n",
        "            else:\n",
        "                print(\"Warning: LibreOffice conversion failed or not available. Will attempt text-only search.\")\n",
        "\n",
        "                hits = []\n",
        "                if is_docx(input_path):\n",
        "                    try:\n",
        "                        from docx import Document\n",
        "                        doc = Document(input_path)\n",
        "                        for p_idx, p in enumerate(doc.paragraphs):\n",
        "                            if search_text.lower() in p.text.lower():\n",
        "                                hits.append((p_idx+1, p.text.strip()))\n",
        "                    except Exception:\n",
        "                        pass\n",
        "                if is_xlsx(input_path):\n",
        "                    try:\n",
        "                        import openpyxl\n",
        "                        wb = openpyxl.load_workbook(input_path, read_only=True, data_only=True)\n",
        "                        for sheet in wb.worksheets:\n",
        "                            for row in sheet.iter_rows(values_only=True):\n",
        "                                for cell in row:\n",
        "                                    if cell and isinstance(cell, str) and search_text.lower() in cell.lower():\n",
        "                                        hits.append((sheet.title, cell.strip()))\n",
        "                    except Exception:\n",
        "                        pass\n",
        "                report_path = os.path.join(out_dir, f\"{basename}_text_search_report.txt\")\n",
        "                with open(report_path, 'w', encoding='utf-8') as f:\n",
        "                    f.write(f\"Search report for '{search_text}' in {input_path}\\n\\n\")\n",
        "                    if hits:\n",
        "                        for h in hits:\n",
        "                            f.write(str(h) + \"\\n\")\n",
        "                    else:\n",
        "                        f.write(\"No hits found or conversion unavailable.\\n\")\n",
        "                print(f\"Text report written to: {report_path}\")\n",
        "                return report_path\n",
        "\n",
        "        elif is_pdf(input_path):\n",
        "            working_pdf = input_path\n",
        "        elif is_image_file(input_path):\n",
        "\n",
        "            img = Image.open(input_path).convert(\"RGB\")\n",
        "            tmp_pdf = os.path.join(tmpdir, basename + \"_from_image.pdf\")\n",
        "            img.save(tmp_pdf, \"PDF\", resolution=100.0)\n",
        "            working_pdf = tmp_pdf\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported file type: \" + input_path)\n",
        "\n",
        "\n",
        "        doc = fitz.open(working_pdf)\n",
        "        matches_per_page = {}\n",
        "        for page_idx in range(len(doc)):\n",
        "\n",
        "            img = render_page_to_image(working_pdf, page_idx, zoom=zoom)\n",
        "            ocr_data = image_to_ocr_data(img)\n",
        "            page_matches = find_matches_in_ocr_data(ocr_data, search_text)\n",
        "            if page_matches:\n",
        "                matches_per_page[page_idx] = page_matches\n",
        "            print(f\"Page {page_idx+1}/{len(doc)} - found {len(page_matches)} matches\")\n",
        "        doc.close()\n",
        "\n",
        "        out_pdf = os.path.join(out_dir, f\"{basename}_boxed.pdf\")\n",
        "\n",
        "        shutil.copyfile(working_pdf, out_pdf)\n",
        "        if matches_per_page:\n",
        "            add_rectangles_to_pdf(out_pdf, matches_per_page, out_pdf, zoom=zoom)\n",
        "            print(f\"Annotated PDF written to: {out_pdf}\")\n",
        "        else:\n",
        "            print(\"No matches found. No annotations added. A copy of the PDF was still created: \" + out_pdf)\n",
        "        return out_pdf\n",
        "\n",
        "    finally:\n",
        "        shutil.rmtree(tmpdir, ignore_errors=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if len(sys.argv) < 3:\n",
        "        print(\"Usage: python auditram_highlighter.py input_file \\\"search text\\\"\")\n",
        "        sys.exit(1)\n",
        "    input_path = sys.argv[1]\n",
        "    search_text = sys.argv[2]\n",
        "    try:\n",
        "        out = process_file(input_path, search_text, zoom=3)\n",
        "        print(\"Done. Output:\", out)\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        raise"
      ]
    }
  ]
}